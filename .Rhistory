?mean
a<-3
b<-5000/4
c <- 25
vector(a,b,c)
mean(a,b,c)
HERO <- a + b + c
Ja <- 45
Nei <- 20
Vet ikke <- 5
"Vet ikke" <- 5
Antall deltakere <- Ja + Nei + "Vet ikke"
Antall deltakere <- Ja + Nei + Vet ikke
"Antall deltakere" <- Ja + Nei + Vet ikke
"Antall deltakere" <- Ja + Nei + "Vet ikke"
"Antall deltakere" <- Ja + Nei + Vet ikke
"Antall deltakere" <- Ja + Nei + Vet ikke
"Antall deltakere" <- (Ja + Nei + Vet ikke)
"Antall deltakere" <- (Ja + Nei + Vet ikke)
"Antall deltakere" <- Ja + Nei + `Vet ikke`
c(2,5,7,8)
k <- c(2,5,7,8)
v_1 <- c(2,5,7,8)    #Vektor 1
v_1 <- c(2,5,7,8)    #Vektor 1
v_2 <- c(1,2,3,4)    #Vektor 2
load("~/Desktop/NHH/Faglig/4. Semester/MET4/Intro til R/testscript.R")
library(quantmod)
library(MASS)
prices <- lapply(symbols, function(symbol) {
data <- getSymbols(symbol, src = "yahoo", from = start_date, to = end_date, auto.assign = FALSE)
Ad(data)
})
2+2
(2+8)/2
2+8/2
a <- 5
a
a*4
b <- 3
c <- a + b
c <- 4
c <- c + 2
d
whatever_we_want <- "hello world"
whatever_we_want
vector1 <- c(3, 5, 7.7, 10, 2, 0.16, -3)
vector1
vector1[1]
vector1[10]
vector1[2:5]
vector1[c(1, 3)]
vector1*2
vector1 - 2
length(vector1)
sum(vector1)
mean(vector1)
sd(vector1)
round(sd(vector1))
round(sd(vector1), digits = 2)
library(readxl)
# Create some data
x <- (-500):500
# We want to calculate mean squirt of abs values of x...
# one way: via temporary variables:
abs.x <- abs(x)
sqrt.abs.x <- sqrt(abs.x)
alt.1 <- mean(sqrt.abs.x)
print(alt.1)
# We could nest the three function calls above
alt.2 <- mean(sqrt(abs(x)))
print(alt.2)
2 |> sqrt()
mean((c(1,2,NA), na.rm=T)
mean(c(1,2,NA), na.rm=T)
c(1,2,NA) |> na.rm=T
c(1,2,NA) |> mean(na.rm=T)
atan2(x=1, y=2)
2 |> atan2(x=1, y=_)
library(magrittr)
2 %>% . ^ 2
2 %>% atan2(1,.)
rm(list = lm())
rm(list = lt())
rm(list = ls())
library(tweedie)
install.packages(tweedie)
install.packages("tweedie")
library(tweedie)
rtweedie(n = 10, mu = 10000, phi = 10 000, power = 1.9)
rtweedie(n = 10, mu = 10000, phi = 10000, power = 1.9)
rtweedie(n = 10, mu = 10000, phi = 1000, power = 1.9)
# Ramping up to 100 000 observations, and finding the mean value of sample
x <- rtweedie(n = 100 000, mu = 10000, phi = 1000, power = 1.9)
x <- rtweedie(n = 100000, mu = 10000, phi = 1000, power = 1.9)
mean(x)
N <- 100
true_mu = 10000
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
# Task 1 - Simulation of M samples
simTweedieTest <- t.test(rtweedie(N, mu = true_mu, phi = 100, power = 1.9),
mu = true_mu)$p.value
simTweedieTest
simulate(simTweedieTest)
simTweedieTest <- t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
simTweedieTest
simTweedieTest
simTweedieTest
simTweedieTest
# Task 1 - Simulation of M samples
simTweedieTest <- function(N){
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)       # Now it gives us the different p-values automatically
simTweedieTest(N)       # Now it gives us the different p-values automatically
MTweedieTests <- function(M, N, alpha) {
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
snippet lib
install.packages("palmerpenguins")
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(tidyverse)
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: load-packages
#| include: false
library(tidyverse)
library(palmerpenguins)
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
install.packages("DescTools")
library(DescTools)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
install.packages("anytime")
library(anytime)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# The URL we will use is stored below:
url <- "https://www.vegvesen.no/trafikkdata/api/"
# Let's figure out which sensor stations that are operable.
# The query below extracts all the stations, with a date for
# when the station was in operation as well as a long/latitude.
qry <-
'
{
trafficRegistrationPoints {
id
name
latestData {
volumeByDay
}
location {
coordinates {
latLon {
lat
lon
}
}
}
}
}
'
# Allright - let's try submitting the query:
stations <-GQL(qry)
length(stations)
length(stations[[1]])
stations[[1]][[1]]
stations[[1]][[1]] %>%
as_tibble()
stations[[1]][[1]]
length(stations)
length(stations[[1]])
stations[[1]] %>%
map(as_tibble) %>%
rbind()
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# This script contains a function for posting GraphQL-queries.
#
# In order to use the function you must have the following
# packages loaded:
# httr
# jsonlite
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
rm(list = ls())
setwd("~/Desktop/iterations-tinnguy3n")
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
# Unlist function
unlist_safe <-
function(x) {
x <- unlist(x)
if (is.null (x)) {
return(NA_character_)
}else{return(x)}
}
# Function transforming metadata to dataframe
transform_metadata_to_df <-
function(y) {
{y <- stations_metadata[[1]]}
{stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, unlist_safe)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)}
}
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
stations_metadata_df
test_stations_metadata_colnames <-
function(df) {
expected_colnames <- c("id", "name", "latestData", "lat", "lon")
if (all(colnames(df) == expected_colnames) == TRUE) {
print("PASS: Data has the correct columns")
} else{
print("FAIL: Columns do not match the correct specification")
}
}
test_stations_metadata_colnames()
test_stations_metadata_colnames(.)
test_stations_metadata_colnames("10601V704982")
test_stations_metadata_colnames("id")
test_stations_metadata_nrows <-
function(df) {
min_expected_rows <- 5000
max_expected_rows <- 10000
if (nrow(df) > min_expected_rows & nrow(df) < max_expected_rows) {
print("PASS: Data has a reasonable number of rows")
} else if (nrow(df) <= min_expected_rows) {
print("FAIL: Data has suspiciously few rows")
} else {
print("FAIL: Data has suspiciously many rows")
}
}
test_stations_metadata_coltypes <-
function(df) {
expected_coltypes <-
c("character", "character", "double", "double", "double")
if (all(df %>%
map_chr( ~ typeof(.)) == expected_coltypes) == TRUE) {
print("PASS: All cols have the correct specifications")
} else{
print("FAIL: Columns do not have the correct specification")
}
}
test_stations_metadata_nmissing <-
function(df) {
max_miss_vals <- 200
if (df %>% map_int( ~ sum(is.na((.)))) %>% sum(.) < max_miss_vals) {
print("PASS: Amount of missing values is reasonable")
} else {
print("FAIL: Too many missing values in data set")
}
}
test_stations_metadata_latestdata_timezone <-
function(df) {
if (attr(df$latestData,"tzone")=="UTC") {
print("PASS: latestData has UTC-time zone")
} else {
print("FAIL: latestData does not have expected UTC-time zone")
}
}
test_stations_metadata <-
function(df){
test_stations_metadata_colnames(df)
test_stations_metadata_coltypes(df)
test_stations_metadata_nmissing(df)
test_stations_metadata_nrows(df)
test_stations_metadata_latestdata_timezone(df)
}
test_stations_metadata(stations_metadata_df)
?iso8601
?days
stations_metadata_df
# Function transforming metadata to dataframe
transform_metadata_to_df <-
function(stations_metadata) {
df <-
stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, unlist_safe)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df) # Returns the dataframe in the function
}
transform_metadata_to_df(.)
transform_metadata_to_df()
# Function transforming metadata to dataframe
transform_metadata_to_df <-
function(df) {
df <-
stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, unlist_safe)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df) # Returns the dataframe in the function
}
transform_metadata_to_df(.)
# a - time function
to_iso8601 <- function(datetime + offset_days) {
# a - time function
to_iso8601 <- function(datetime, offset_days) {
# Converts string to datetime object
datetime_var <- anytime(datetime)
adjusted_datetime <- datetime_var + days(offset_days)
iso8601_z <- format(adjusted_datetime,
format = "%Y-%m-%dT%H:%M:%SZ",
tz = "UTC")
return(iso8601_z)
}
# Test the time function
to_iso8601(as_datetime("2016-09-01 10:11:12"), 0)
to_iso8601(as_datetime("2016-09-01 10:11:12"), -4)

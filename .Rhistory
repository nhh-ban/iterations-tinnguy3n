t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
# Task 1 - Simulation of M samples
simTweedieTest <- t.test(rtweedie(N, mu = true_mu, phi = 100, power = 1.9),
mu = true_mu)$p.value
simTweedieTest
simulate(simTweedieTest)
simTweedieTest <- t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
simTweedieTest
simTweedieTest
simTweedieTest
simTweedieTest
# Task 1 - Simulation of M samples
simTweedieTest <- function(N){
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)       # Now it gives us the different p-values automatically
simTweedieTest(N)       # Now it gives us the different p-values automatically
MTweedieTests <- function(M, N, alpha) {
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
snippet lib
install.packages("palmerpenguins")
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(tidyverse)
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: load-packages
#| include: false
library(tidyverse)
library(palmerpenguins)
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
install.packages("DescTools")
library(DescTools)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
install.packages("anytime")
library(anytime)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# The URL we will use is stored below:
url <- "https://www.vegvesen.no/trafikkdata/api/"
# Let's figure out which sensor stations that are operable.
# The query below extracts all the stations, with a date for
# when the station was in operation as well as a long/latitude.
qry <-
'
{
trafficRegistrationPoints {
id
name
latestData {
volumeByDay
}
location {
coordinates {
latLon {
lat
lon
}
}
}
}
}
'
# Allright - let's try submitting the query:
stations <-GQL(qry)
length(stations)
length(stations[[1]])
stations[[1]][[1]]
stations[[1]][[1]] %>%
as_tibble()
stations[[1]][[1]]
length(stations)
length(stations[[1]])
stations[[1]] %>%
map(as_tibble) %>%
rbind()
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# Problem 2
# Unlist function
unlist_safe <-
function(x) {
x <- unlist(x)
if (is.null (x)) {
return(NA_character_)
}else{return(x)}
}
# Function transforming metadata to dataframe
transform_metadata_to_df <-
function(df) {
df <-
stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, unlist_safe)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df) # Returns the data frame in the function
}
source("functions/data_transformations.r")
setwd("~/Desktop/iterations-tinnguy3n")
source("functions/data_transformations.r")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
test_stations_metadata_colnames <-
function(df) {
expected_colnames <- c("id", "name", "latestData", "lat", "lon")
if (all(colnames(df) == expected_colnames) == TRUE) {
print("PASS: Data has the correct columns")
} else{
print("FAIL: Columns do not match the correct specification")
}
}
# Function to see if the dataframe have a reasonable number of rows or not.
test_stations_metadata_nrows <-
function(df) {
min_expected_rows <- 5000
max_expected_rows <- 10000
if (nrow(df) > min_expected_rows & nrow(df) < max_expected_rows) {
print("PASS: Data has a reasonable number of rows")
} else if (nrow(df) <= min_expected_rows) {
print("FAIL: Data has suspiciously few rows")
} else {
print("FAIL: Data has suspiciously many rows")
}
}
# Function to see if the columns have correct specification or not.
test_stations_metadata_coltypes <-
function(df) {
expected_coltypes <-
c("character", "character", "double", "double", "double")
if (all(df %>%
map_chr( ~ typeof(.)) == expected_coltypes) == TRUE) {
print("PASS: All cols have the correct specifications")
} else{
print("FAIL: Columns do not have the correct specification")
}
}
# Function testing if number of values is reasonable or not.
test_stations_metadata_nmissing <-
function(df) {
max_miss_vals <- 200
if (df %>% map_int( ~ sum(is.na((.)))) %>% sum(.) < max_miss_vals) {
print("PASS: Amount of missing values is reasonable")
} else {
print("FAIL: Too many missing values in data set")
}
}
# Funtion testing if the dataframe has the "UTC" timezone or not.
test_stations_metadata_latestdata_timezone <-
function(df) {
if (attr(df$latestData,"tzone")=="UTC") {
print("PASS: latestData has UTC-time zone")
} else {
print("FAIL: latestData does not have expected UTC-time zone")
}
}
# A summary of all the functions above.
test_stations_metadata <-
function(df){
test_stations_metadata_colnames(df)
test_stations_metadata_coltypes(df)
test_stations_metadata_nmissing(df)
test_stations_metadata_nrows(df)
test_stations_metadata_latestdata_timezone(df)
}
test_stations_metadata(stations_metadata_df)
# a - time function
to_iso8601 <- function(datetime, offset_days) {
# Converts string to datetime object
datetime_var <- anytime(datetime)
# Add offset to original time
adjusted_datetime <- datetime_var + days(offset_days)
# UTC and add iso8601 formatting with Z
iso8601_z <- format(adjusted_datetime,
format = "%Y-%m-%dT%H:%M:%SZ",
tz = "UTC")
return(iso8601_z)
}
# Test the time function
to_iso8601(as_datetime("2016-09-01 10:11:12"), 0)   # Works
to_iso8601(as_datetime("2016-09-01 10:11:12"), -4)  # Works
vol_qry <- function(id, from, to) {
query <- glue('{{
trafficData(trafficRegistrationPointId: "97411V72313") {
volume {
byHour(from: "2022-05-01T06:55:47Z", to: "2022-05-08T06:55:47Z") {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}}', id = id, from = from, to = to)
return(query)
}
# Testing the query function
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
query <- glue('{{
trafficData(trafficRegistrationPointId: "97411V72313") {
volume {
byHour(from: "{from}", to: "{to}") {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}}', id = id, from = from, to = to)
vol_qry <- function(id, from, to) {
query <- glue('{{
trafficData(trafficRegistrationPointId: "97411V72313") {
volume {
byHour(from: "{from}", to: "{to}") {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}}', id = id, from = from, to = to)
return(query)
}
# Testing the query function
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
vol_qry <- function(id, from, to) {
query <- glue('{{
trafficData(trafficRegistrationPointId: "{id}") {
volume {
byHour(from: "{from}", to: "{to}") {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}}', id = id, from = from, to = to)
return(query)
}
# Testing the query function
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
# Problem 4b - GQL for volumes
library(glue)
# Testing the query function
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
vol_qry <- function(id, from, to) {
query <- glue('{{
trafficData(trafficRegistrationPointId: "{id}") {{
volume {{
byHour(from: "{from}", to: "{to}") {{
edges {{
node {{
from
to
total {{
volumeNumbers {{
volume
}}
}}
}}
}}
}}
}}
}}
}}', id = id, from = from, to = to)
return(query)
}
# Testing the query function
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
source("gql-queries/vol_qry.r")
